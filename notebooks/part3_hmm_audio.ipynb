{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0b3407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../code')\n",
    "\n",
    "from pomegranate import HiddenMarkovModel, DiscreteDistribution, NormalDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56e16ef0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'TpHmmUtilit'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m@author: barthes\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03mVersion 1.4\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m \u001b[33;03mAffichage de la série temporelle d'un mot + différentes repésentations des features pour les 3 méthodes \u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m#%%\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mTpHmmUtilit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Words\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m#%%\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'TpHmmUtilit'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: barthes\n",
    "Version 1.4\n",
    "revision nov 2024\n",
    "revision nov 2025\n",
    "Script permettant de charger les fichiers audio et de calculer les features de chaque trame à l'aide des 3 méthodes disponibles (spectrum, filter et mfcc)\n",
    "Affichage de la série temporelle d'un mot + différentes repésentations des features pour les 3 méthodes \n",
    "\"\"\"\n",
    "#%%\n",
    "from TpHmmUtilit import Words\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#%%\n",
    "winlen=0.02         # taille d'une frame en seconde\n",
    "winstep=0.01        # decalage temporel entre une frame et la suivante en seconde\n",
    "nfft=256            # Méthode Spectrum : Nombre de points pour le calcul de la FFT => spectre nfft/2 + 1 valeurs\n",
    "nfilt=26            # Méthode filter : Nonbre de filtres calculés \n",
    "numcep=12           # Méthode mfcc : Nombre de coefficients de Mel  \n",
    "dossierAudio = 'audio'\n",
    "\n",
    "words=Words(rep=dossierAudio,name='exemple 1',numcep=numcep,winlen=winlen,winstep=winstep,nfilt=nfilt,nfft=nfft,filterLow=False,noise=0)\n",
    "\n",
    "listeDesMotsDisponibles = words.getLabels()\n",
    "print('Les mots disponibles dans le dossier {} sont :\\n{}'.format(dossierAudio,listeDesMotsDisponibles))\n",
    "\n",
    "#%% On choit un des mots\n",
    "myWord='banana'      # mot choisi parmi 'apple', 'banana', 'kiwi', 'lime', 'orange', 'peach', 'pineapple'\n",
    "\n",
    "#%%\n",
    "# Affiche l'enregistrement d'un mot et ses features pour les 3 méthodes d'extraction\n",
    "\"\"\"record = 0\n",
    "words.plotOneWord(label=myWord,num=record)\n",
    "record = 1\n",
    "words.plotOneWord(label=myWord,num=record)\n",
    "record = 2\n",
    "words.plotOneWord(label=myWord,num=record)\n",
    "record = 3\n",
    "words.plotOneWord(label=myWord,num=record)\n",
    "record = 4\n",
    "words.plotOneWord(label=myWord,num=record)\n",
    "record = 5\n",
    "words.plotOneWord(label=myWord,num=record)\n",
    "record = 6\n",
    "words.plotOneWord(label=myWord,num=record)\n",
    "record = 7\n",
    "words.plotOneWord(label=myWord,num=record)\n",
    "record = 8\n",
    "words.plotOneWord(label=myWord,num=record)\n",
    "record = 9\n",
    "words.plotOneWord(label=myWord,num=record)\n",
    "record = 10\n",
    "words.plotOneWord(label=myWord,num=record)\n",
    "record = 11\n",
    "words.plotOneWord(label=myWord,num=record)\n",
    "record = 12\n",
    "words.plotOneWord(label=myWord,num=record)\n",
    "record = 13\n",
    "words.plotOneWord(label=myWord,num=record)\n",
    "record = 14\n",
    "words.plotOneWord(label=myWord,num=record)\"\"\"\n",
    "\n",
    "\n",
    "#%% Pour les 3 méthodes affiche les matrices de corrélation des features\n",
    "#words.CorrFeatures(label=myWord)\n",
    "\n",
    "#%%\n",
    "# Pour les 3 méthodes d'extraction on affiche les histogrammes des différentes features Fi du mot choisi (all records)\n",
    "\n",
    "\"\"\"words.histFeatures(myWord,'spectrum',0,31)\n",
    "words.histFeatures(myWord,'spectrum',32,63) # Features 0 -> 63 de la méthode spectrum\n",
    "words.histFeatures(myWord,'spectrum',64,91)\n",
    "words.histFeatures(myWord,'spectrum',92,128)# Features 64->128 de la méthode spectrum\n",
    "\n",
    "words.histFeatures(myWord,'filter',0,25)          # Features 0 -> 25 de la méthode filtre\n",
    "words.histFeatures(myWord,'mfcc',0,11) \"\"\"\n",
    "# Features 0-> 11 de la méthode mfcc\n",
    "\n",
    "#%%\n",
    "# Pour les 3 méthodes d'extraction on affiche les features Fx et Fy du mot dans le plan X, Y (all records)\n",
    "\n",
    "X=0                # Feature X en abcisse pour affichage\n",
    "Y=1                # Feature Y en ordonnée pour affichage\n",
    "\n",
    "words.plotFeatureXY(myWord,methode='mfcc',I=X,J=Y)   # Affiche pour tous les mots de myWord les features Fx et Fy pour les 3 méthodes\n",
    "#%% Pour les 3 méthodes d'extraction on représente la TSNE des features (all records) de myWord\n",
    "#words.TSNEFeatures2(label=myWord)\n",
    "plt.show()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0948fcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Nov  4  2020\n",
    "Modifié 28/10/2024, 20/11/2025\n",
    "@author: barthes\n",
    "Nécessite pomegranate > 1.X.X\n",
    "Version 1.3\n",
    "Script exemple permettant l'apprentissage d'un mot à partir d'une chaine\n",
    "de Markov cachée à l'aide d'une des 3 méthodes de calcul des features \n",
    "\"\"\"\n",
    "#%%\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from TpHmmUtilit import GaussianHMM, Words\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#%% Ne pas modifier\n",
    "winlen = 0.02        # taille d'une frame en seconde\n",
    "winstep = 0.01       # decalage temporel entre une frame et la suivante en seconde\n",
    "highfreq = 4000      # frequence max en Hz\n",
    "lowfreq = 0          # fréquence min en Hz\n",
    "nfilt = 26           # Nonbre de filtres calculés (methode filter)\n",
    "numcep = 12          # Nombre de coefficients de Mel (methode mfcc)\n",
    "nfft = 256           # Nombre de points pour le calcul du spectre (methode spectrum)\n",
    "\n",
    "#%%\n",
    "methode   = 'spectrum'   # Choix de la feature (spectrum, filter ou mfcc)\n",
    "myWord    = 'banana' # mot choisi\n",
    "featStart = 0        # Choix de la composante min de feature\n",
    "featStop  = 2        # Choix de la composante max de feature (inclus)\n",
    "Nstates   = 2      # Nombre d'état de la chaine de Markov\n",
    "\n",
    "for Nstates in range(2, 4):  # Nombre d'états de la chaîne de Markov (2 à 5)\n",
    "    for featStop in range(2, 4):  # Composante max de feature (2 à 5)\n",
    "        featStart = 0  # Composante min de feature\n",
    "        print(f\"Testing with Nstates={Nstates}, featStop={featStop}\")\n",
    "\n",
    "        #%% lecture des fichiers audio et calcul des features. On bruite légérement les enregistrements\n",
    "        words = Words(rep='audio',\n",
    "                      name='audio',\n",
    "                      numcep=numcep,\n",
    "                      lowfreq=lowfreq,\n",
    "                      highfreq=None,\n",
    "                      winlen=winlen,\n",
    "                      winstep=winstep,\n",
    "                      nfilt=nfilt,\n",
    "                      nfft=nfft,\n",
    "                      noise=50)\n",
    "\n",
    "        # On extrait une liste avec les 15 enregistrements du mot défini dans myWord\n",
    "        # en utilisant la méthode definie par la variable methode\n",
    "        liste = words.getFeatList(label=myWord,\n",
    "                                  methode=methode,\n",
    "                                  featStart=featStart,\n",
    "                                  featStop=featStop)\n",
    "\n",
    "        #%% Création et apprentissage de la HMM\n",
    "        Model = GaussianHMM(liste=liste, Nstates=Nstates)    # création et entrainement du modèle\n",
    "\n",
    "        #%% FIGURE 1 : ellipses gaussiennes dans différents plans Fx, Fy\n",
    "\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 4), subplot_kw={'aspect': 'equal'})\n",
    "        \n",
    "        # Plan (Feat 0, Feat 1)\n",
    "        plt.sca(axes[0])\n",
    "        Model.plotGaussianConfidenceEllipse(words, Fx=0, Fy=1, color='b')\n",
    "        plt.title(f'{myWord} - {methode} (Feat 0,1)')\n",
    "        plt.xlabel('Feat 0')\n",
    "        plt.ylabel('Feat 1')\n",
    "        \n",
    "        # Plan (Feat 0, Feat 2)\n",
    "        plt.sca(axes[1])\n",
    "        Model.plotGaussianConfidenceEllipse(words, Fx=0, Fy=2, color='b')\n",
    "        plt.title(f'{myWord} - {methode} (Feat 0,2)')\n",
    "        plt.xlabel('Feat 0')\n",
    "        plt.ylabel('Feat 2')\n",
    "        \n",
    "        # Plan (Feat 1, Feat 2)\n",
    "        plt.sca(axes[2])\n",
    "        Model.plotGaussianConfidenceEllipse(words, Fx=1, Fy=2, color='b')\n",
    "        plt.title(f'{myWord} - {methode} (Feat 1,2)')\n",
    "        plt.xlabel('Feat 1')\n",
    "        plt.ylabel('Feat 2')\n",
    "        \n",
    "        plt.tight_layout()\"\"\"\n",
    "\n",
    "        #%% Visualisation des paramètres de la chaine de Markov (console)\n",
    "\n",
    "        np.set_printoptions(precision=2, floatmode='fixed', suppress=False)\n",
    "        print('Matrice de transition :\\n{}'.format(Model.getTrans()))\n",
    "        print('Prob initiale : \\n{}'.format(Model.getPi0()))\n",
    "        for i in range(Nstates):\n",
    "            print('\\nEtat {} :'.format(i))\n",
    "            print('cov:\\n{}'.format(Model.getCov()[i]))\n",
    "            print('Mu:\\n{}'.format(Model.getMu()[i]))\n",
    "\n",
    "        #%% Séquences d'états optimales pour chacun des 15 enregistrements\n",
    "\n",
    "        predictedStates = Model.predict(liste)\n",
    "        for i, l in enumerate(predictedStates):\n",
    "            print('Séquence des Etats optimaux enregistrement {} de {} :\\n {}'.format(i, myWord, l))\n",
    "\n",
    "        #%% Log-probabilité de chaque enregistrement et FIGURE 2\n",
    "\n",
    "        logprobs_tensors = Model.log_prob(liste)\n",
    "        print('Log de la probabilité des {} enregistrements de {}:\\n{}\\n'.format(len(liste), myWord, logprobs_tensors))\n",
    "\n",
    "        logprobs = np.array([float(lp) for lp in logprobs_tensors])\n",
    "\n",
    "        plt.figure(figsize=(8, 4))\n",
    "\n",
    "        x = np.arange(len(logprobs))\n",
    "        for i in range(len(logprobs)):\n",
    "            plt.plot([x[i], x[i]], [0, logprobs[i]], 'k-', linewidth=1)\n",
    "            plt.plot(x[i], logprobs[i], 'bo', markersize=5)\n",
    "\n",
    "        plt.xlabel('Index enregistrement')\n",
    "        plt.ylabel('log P( séquence | HMM )')\n",
    "        plt.title(f'Nombre de state {Nstates}, Nombre de feature {featStop - featStart + 1}')\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22892a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Partie 3 : Apprentissage d'une chaine de Markov cachée pour chaque mot\n",
    "et évaluation par matrice de confusion / F1-score.\n",
    "\n",
    "A adapter pour les différentes méthodes d'extraction (mfcc, filter, spectrum)\n",
    "et différents hyperparamètres (Nstates, nombre de features utilisées).\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from TpHmmUtilit import GaussianHMM, Words\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Paramètres généraux (ne pas toucher pour le TP sauf si besoin)\n",
    "# -------------------------------------------------------------------\n",
    "winlen  = 0.02       # durée frame (s)\n",
    "winstep = 0.01       # décalage entre frames (s)\n",
    "highfreq = 4000\n",
    "lowfreq  = 0\n",
    "nfilt  = 26          # method filter\n",
    "numcep = 12          # method mfcc\n",
    "nfft   = 256         # method spectrum\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Hyperparamètres à tester\n",
    "# -------------------------------------------------------------------\n",
    "methode   = 'spectrum'   # 'mfcc', 'filter', 'spectrum'\n",
    "featStart = 0        # composante min\n",
    "featStop  = 3        # composante max incluse -> ici 6 features (0..5)\n",
    "Nstates   = 2        # nombre d'états du HMM\n",
    "Nexp      = 5       # nombre de répétitions de l'expérience\n",
    "\n",
    "print(f\"Méthode = {methode}, Nstates = {Nstates}, features = {featStart}..{featStop}, Nexp = {Nexp}\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Listes pour stocker toutes les prédictions de toutes les expériences\n",
    "# -------------------------------------------------------------------\n",
    "all_true_labels = []\n",
    "all_pred_labels = []\n",
    "\n",
    "for exp in range(Nexp):\n",
    "    print(f\"\\n===== Expérience {exp+1}/{Nexp} =====\")\n",
    "\n",
    "    # ----------------------------------------------------------------\n",
    "    # 1. Chargement des données avec bruitage pour l'apprentissage\n",
    "    #    (noise=500 comme demandé dans l'énoncé)\n",
    "    # ----------------------------------------------------------------\n",
    "    words = Words(rep='audio',\n",
    "                  name='audio',\n",
    "                  numcep=numcep,\n",
    "                  lowfreq=lowfreq,\n",
    "                  highfreq=None,\n",
    "                  winlen=winlen,\n",
    "                  winstep=winstep,\n",
    "                  nfilt=nfilt,\n",
    "                  nfft=nfft,\n",
    "                  noise=500)\n",
    "\n",
    "    # Liste des mots disponibles (apple, banana, kiwi, ...)\n",
    "    listeDesMotsDisponibles = words.getLabels()\n",
    "    Q = len(listeDesMotsDisponibles)\n",
    "    print(\"Mots du dictionnaire :\", listeDesMotsDisponibles)\n",
    "\n",
    "    # ----------------------------------------------------------------\n",
    "    # 2. Apprentissage : un HMM par mot (sur les 10 premiers enregistrements)\n",
    "    # ----------------------------------------------------------------\n",
    "    models = []\n",
    "    for word in listeDesMotsDisponibles:\n",
    "        # dataset='train' -> 10 premiers enregistrements bruités\n",
    "        liste_train = words.getFeatList(label=word,\n",
    "                                        methode=methode,\n",
    "                                        featStart=featStart,\n",
    "                                        featStop=featStop,\n",
    "                                        dataset='train')\n",
    "        model = GaussianHMM(liste=liste_train, Nstates=Nstates)\n",
    "        models.append(model)\n",
    "\n",
    "    # ----------------------------------------------------------------\n",
    "    # 3. Validation : 5 derniers enregistrements (dataset='val')\n",
    "    # ----------------------------------------------------------------\n",
    "    for true_index, word in enumerate(listeDesMotsDisponibles):\n",
    "\n",
    "        # liste de 5 séquences pour ce mot\n",
    "        liste_val = words.getFeatList(label=word,\n",
    "                                      methode=methode,\n",
    "                                      featStart=featStart,\n",
    "                                      featStop=featStop,\n",
    "                                      dataset='val')\n",
    "\n",
    "        for seq in liste_val:\n",
    "            # calcul des log-probabilités de cette séquence pour chaque modèle\n",
    "            scores = []\n",
    "            for model in models:\n",
    "                # log_prob attend une liste de séquences -> on lui passe [seq]\n",
    "                lp = model.log_prob([seq])[0]\n",
    "                scores.append(float(lp))\n",
    "\n",
    "            # mot prédit = modèle qui donne la probabilité maximale\n",
    "            pred_index = int(np.argmax(scores))\n",
    "\n",
    "            all_true_labels.append(true_index)\n",
    "            all_pred_labels.append(pred_index)\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 4. Évaluation globale : matrice de confusion et F1-score\n",
    "# --------------------------------------------------------------------\n",
    "all_true_labels = np.array(all_true_labels)\n",
    "all_pred_labels = np.array(all_pred_labels)\n",
    "\n",
    "cm = confusion_matrix(all_true_labels,\n",
    "                      all_pred_labels,\n",
    "                      labels=np.arange(len(listeDesMotsDisponibles)))\n",
    "\n",
    "f1 = f1_score(all_true_labels,\n",
    "              all_pred_labels,\n",
    "              average='macro')\n",
    "\n",
    "print(\"\\n====================== RÉSULTATS GLOBAUX ======================\")\n",
    "print(\"Mots (ordre des classes) :\", listeDesMotsDisponibles)\n",
    "print(\"\\nMatrice de confusion (lignes = vrais mots, colonnes = mots prédits) :\\n\")\n",
    "print(cm)\n",
    "print(\"\\nF1-score macro :\", f1)\n",
    "print(\"===============================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fbfa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "from TpHmmUtilit import GaussianHMM, Words\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Paramètres globaux\n",
    "# -------------------------------------------------------\n",
    "winlen  = 0.02\n",
    "winstep = 0.01\n",
    "nfilt   = 26\n",
    "numcep  = 12\n",
    "nfft    = 256\n",
    "lowfreq = 0\n",
    "highfreq = None\n",
    "\n",
    "methode   = \"mfcc\"         # uniquement MFCC comme demandé\n",
    "featStart = 0\n",
    "featStop  = 4              # 6 features MFCC (0..5)\n",
    "Nstates   = 3             # nombre d'états HMM\n",
    "K         = 3              # K-fold cross validation\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 1) Construire la base augmentée (10 versions bruitées)\n",
    "# -------------------------------------------------------\n",
    "print(\"Création de la base augmentée...\")\n",
    "repertoire = 'audio1'\n",
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        words = Words(rep=repertoire, name=repertoire,\n",
    "                      numcep=numcep, lowfreq=lowfreq, highfreq=highfreq,\n",
    "                      winlen=winlen, winstep=winstep, nfilt=nfilt, nfft=nfft,\n",
    "                      noise=500)   # bruit\n",
    "    else:\n",
    "        words = words + Words(rep=repertoire, name=repertoire,\n",
    "                              numcep=numcep, lowfreq=lowfreq, highfreq=highfreq,\n",
    "                              winlen=winlen, winstep=winstep, nfilt=nfilt, nfft=nfft,\n",
    "                              noise=500)\n",
    "\n",
    "# obtenir les labels des mots (apple, kiwi, …)\n",
    "mots = words.getLabels()\n",
    "Q = len(mots)\n",
    "\n",
    "print(\"Mots :\", mots)\n",
    "# Taille totale = somme des séquences extraites pour chaque mot\n",
    "total_samples = sum(len(words.getFeatList(label=mot,\n",
    "                                          methode=methode,\n",
    "                                          featStart=featStart,\n",
    "                                          featStop=featStop,\n",
    "                                          dataset='all'))\n",
    "                    for mot in mots)\n",
    "\n",
    "print(\"Taille totale de la base augmentée :\", total_samples, \"enregistrements\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 2) Construire une liste globale de toutes les features\n",
    "# -------------------------------------------------------\n",
    "\n",
    "print(\"Extraction MFCC...\")\n",
    "\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "for idx, mot in enumerate(mots):\n",
    "    # Récupérer *tous* les enregistrements de ce mot dans la base augmentée\n",
    "    liste = words.getFeatList(label=mot,\n",
    "                              methode=methode,\n",
    "                              featStart=featStart,\n",
    "                              featStop=featStop,\n",
    "                              dataset='all')        # IMPORTANT : on prend tout\n",
    "\n",
    "    for seq in liste:\n",
    "        all_features.append(seq)\n",
    "        all_labels.append(idx)\n",
    "\n",
    "all_features = np.array(all_features, dtype=object)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "print(\"Total séquences :\", len(all_features))\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 3) K-Fold cross-validation\n",
    "# -------------------------------------------------------\n",
    "\n",
    "kf = KFold(n_splits=K, shuffle=True, random_state=42)\n",
    "f1_scores = []\n",
    "\n",
    "print(\"\\n===== Début du K-Fold (k=3) =====\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(all_features), start=1):\n",
    "    print(f\"\\n--- Fold {fold}/{K} ---\")\n",
    "\n",
    "    # Séparer les séquences\n",
    "    X_train = all_features[train_idx]\n",
    "    y_train = all_labels[train_idx]\n",
    "    X_val   = all_features[val_idx]\n",
    "    y_val   = all_labels[val_idx]\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # 3.a Apprentissage : un HMM par mot\n",
    "    # ---------------------------------------------------\n",
    "\n",
    "# 3.a Apprentissage : un HMM par mot\n",
    "    models = []\n",
    "\n",
    "    class DummyList:\n",
    "        \"\"\"Objet minimal pour imiter la structure retournée par getFeatList.\"\"\"\n",
    "        def __init__(self, liste, label, methode, featStart, featStop):\n",
    "            self.liste = liste          # liste de séquences (numpy arrays)\n",
    "            self._label = label         # nom du mot (string)\n",
    "            self._methode = methode     # 'mfcc'\n",
    "            self._featStart = featStart\n",
    "            self._featStop = featStop\n",
    "\n",
    "        def getLabel(self):\n",
    "            return self._label\n",
    "\n",
    "        def getMethode(self):\n",
    "            return self._methode\n",
    "\n",
    "        def getFeatStart(self):\n",
    "            return self._featStart\n",
    "\n",
    "        def getFeatStop(self):\n",
    "            return self._featStop\n",
    "\n",
    "    for mot_index in range(Q):\n",
    "\n",
    "        # Séquences du mot correspondant dans X_train\n",
    "        seqs = [X_train[i] for i in range(len(X_train)) if y_train[i] == mot_index]\n",
    "\n",
    "        # Label du mot (ex: 'apple', 'banana', ...)\n",
    "        label_mot = mots[mot_index]\n",
    "\n",
    "        dummy = DummyList(seqs, label_mot, methode, featStart, featStop)\n",
    "\n",
    "        model = GaussianHMM(liste=dummy, Nstates=Nstates)\n",
    "        models.append(model)\n",
    "\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # 3.b Validation : prédire chaque séquence du fold\n",
    "    # ---------------------------------------------------\n",
    "    y_pred = []\n",
    "\n",
    "    for seq in X_val:\n",
    "        scores = []\n",
    "        for model in models:\n",
    "            scores.append(float(model.log_prob([seq])[0]))\n",
    "        y_pred.append(int(np.argmax(scores)))\n",
    "\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # ---------------------------------------------------\n",
    "    # 3.c Calcul du F1-score\n",
    "    # ---------------------------------------------------\n",
    "    f1 = f1_score(y_val, y_pred, average='macro')\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    print(f\"F1-score du fold {fold} :\", f1)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 4) Résultat final\n",
    "# -------------------------------------------------------\n",
    "\n",
    "print(\"\\n================ RESULTATS K-FOLD ================\")\n",
    "print(\"F1-scores individuels :\", f1_scores)\n",
    "print(\"F1-score moyen :\", np.mean(f1_scores))\n",
    "print(\"=================================================\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
