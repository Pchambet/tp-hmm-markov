# Markov Chains & Hidden Markov Models

**From rain prediction to speech recognition — how sequential patterns emerge from hidden states.**

This project implements Markov Chains and Hidden Markov Models (HMMs) across two domains: meteorological modeling and isolated word recognition. The progression is deliberate: we start with the simplest possible sequential model (a 2-state chain), add a hidden layer, then apply the same framework to a fundamentally different problem (audio classification) — showing that the math transfers directly.

## Part 1 — Discrete Markov Chain (Weather)

A 2-state chain models dry/rainy day alternation. The transition matrix is estimated from real rainfall data (5-minute resolution), and we compare simulated sequences against measured statistics.

**Key question:** can two parameters (p, q) reproduce the distribution of dry and rainy spell durations observed over months of real data?

**What we found:**
- The hand-tuned model captures the qualitative shape but misses the heavy tails of dry spell durations
- Maximum-likelihood estimation from measured mean durations yields a closer fit
- The stationary distribution matches the empirical rainfall frequency (~7%), validating the Markov assumption for short-range dependence

## Part 2 — Hidden Markov Model (Weather)

The observable (rain / no rain) is now generated by a hidden state representing sky conditions: *Clear*, *Cloudy*, *Overcast*. This adds expressiveness — the same "no rain" observation can come from genuinely clear skies or from clouds that haven't broken yet.

**Two approaches:**
1. **Manual model** — transition and emission matrices set by meteorological intuition
2. **Learned model** — parameters estimated via Baum-Welch (EM algorithm) on the real rainfall series

**Key result:** the learned model recovers a transition structure where the "Overcast" state acts as a rain gateway (high emission probability), while "Clear" → "Cloudy" transitions dominate, matching physical intuition. The duration distributions improve significantly over the simple Markov chain.

## Part 3 — Gaussian HMM (Speech Recognition)

Each spoken word is modeled as a sequence of acoustic frames, where hidden states represent phonetic segments. One HMM is trained per word class, and classification uses maximum-likelihood decoding.

**Pipeline:**
1. Audio files → frame-level feature extraction (Spectrum, Filter banks, MFCC)
2. One Gaussian HMM trained per word (e.g. "apple", "banana", "eight"...)
3. Classification by selecting the model with highest log-likelihood for a test utterance
4. Evaluation via k-fold cross-validation and confusion matrices

**Features compared:**

| Feature | Dimension | What it captures |
|---|---|---|
| Spectrum | 129 | Raw frequency content (FFT) |
| Filter bank | 26 | Perceptually-spaced energy bands |
| MFCC | 12 | Compact cepstral representation |

**Key result:** MFCC features consistently outperform raw spectrum and filter banks — the decorrelation and dimensionality reduction of the cepstral transform provides a better feature space for HMM training with limited data.

## Project structure

```
├── notebooks/
│   ├── part1_markov_pluie.ipynb     ← Discrete Markov chain on rainfall data
│   ├── part2_hmm_pluie.ipynb        ← HMM with Baum-Welch learning
│   └── part3_hmm_audio.ipynb        ← Gaussian HMM for word recognition
├── code/
│   ├── base.py                      ← MFCC / filter bank computation
│   ├── sigproc.py                   ← Signal processing primitives
│   ├── duree.py                     ← Spell duration analysis
│   ├── TpHmmUtilit.py               ← HMM utilities (GaussianHMM, Words)
│   └── exercice1aCompeleter .py     ← Markov chain simulation
├── data/
│   └── audio1/                      ← Spoken word recordings (.wav)
├── report/
│   ├── main.tex                     ← LaTeX source
│   └── main.pdf                     ← Compiled report
├── docs/
│   └── assignment.pdf               ← Original assignment
└── README.md
```

## Tech stack

Python 3 · NumPy · SciPy · Matplotlib · scikit-learn · pomegranate

## Installation

```bash
python3 -m venv .venv && source .venv/bin/activate
pip install numpy scipy matplotlib scikit-learn pomegranate
```

> **Note:** This project uses `pomegranate >= 1.1`. The API differs significantly from v0.x.

## Author

Pierre Chambet — Télécom SudParis, 2025.

## License

MIT
